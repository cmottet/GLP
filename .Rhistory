for (i in 1:length(trainData)){
k <- chooseBestkFourier(trainData[[i]], testData[[i]])
filteredFourier <- filterFourierCoefficients(log(trainData[[i]]$valueMean + 1), k = k )
print(k)
t <- testFourier$t
predictions <- with(filteredFourier, buildSignal(t, cn, f ))
trainingData$LogFourierResiduals[t] <- log(testData[[i]]$valueMean + 1) - predictions
trainingData$LogFourierPrediction[t] <- predictions
}
# logDemand <- fo
k <- chooseBestkFourier(trainData[[i]], testData[[i]])
chooseBestkFourier()
chooseBestkFourier
library(devtool)
library(devtools)
install.packages(("lpSolve", "GenSA","dplyr","plyr","gtools","ggplot2"))
install.packages(c("lpSolve", "GenSA","dplyr","plyr","gtools","ggplot2"))
install.packages("bootstrap")
installed.packages("ks")
install.packages("ks")
install.packages("rgl")
library(rgl)
install.packages("rgl")
library(devtools)
install.packages("rgl")
library(rgl)
library(devtool)
library(devtools)
install.packages("rgl")
library(rgl)
library(GLP)
library(GLP)
library(GLP)
bootstrap?
}}
?bootstrap
bootstrap
library(bootstrap)
bootstrap
set.seed(100)
a=1
b = 2
runif
runif()
runif(1)
runif(1)
set.seed(100)
runif(1)
bootstrap()
bootstrap
is.null(1)
library(GLP)
method = c("hyperrectangle","ellipsoid", "both")
nboot = 1E3
alpha = 0.05
method <- match.arg(method)
method = "hyperrectangle"
tmp <- cleanAndcheckdAndm(d,m)
d <- tmp$d
m = 1:4
d = 0
BonferroniEllipse <- 1
BonferroniRectangle  <- if (bonferroni) length(d) + length(m) else 1
bonferroni = TRUE
sample = rnomr(500)
sample = rnorm(500)
BonferroniEllipse <- 1
BonferroniRectangle  <- if (bonferroni) length(d) + length(m) else 1
fboot <- lapply(a,buildMomentAndDerivativesFunctions,  m = m, d = d)
bootstrapedMomentAndDerivatives <- lapply(fboot,getBootstrapedValues, sample = sample, nboot = nboot, mc.cores = mc.cores, seed = seed)
seed = 100
bootstrapedMomentAndDerivatives <- lapply(fboot,getBootstrapedValues, sample = sample, nboot = nboot, mc.cores = mc.cores, seed = seed)
mc.cores = 1
bootstrapedMomentAndDerivatives <- lapply(fboot,getBootstrapedValues, sample = sample, nboot = nboot, mc.cores = mc.cores, seed = seed)
fboot
m
d
d = 1:2
d = d[FALSE]
d
m = 0:4
fboot <- lapply(a,buildMomentAndDerivativesFunctions,  m = m, d = d)
fboot
bootstrapedMomentAndDerivatives <- lapply(fboot,getBootstrapedValues, sample = sample, nboot = nboot, mc.cores = mc.cores, seed = seed)
warnings()
bootstrapedMomentAndDerivatives
sessionInfo()
installed.packages("ks")
library(GLP)
?GenSA
library(GenSA)
?GenSA
evalConst = function(x,constFun,paramConstFun){
output = matrix(0,nrow= length(constFun),ncol = length(x))
for (i in 1:length(constFun)) output[i,] = do.call(constFun[[i]],list(x = x,paramConstFun = paramConstFun))
return(output)
}
innerOptimizationFunction = function(x,lpdual,phase,constFun,paramConsFun, objFun = NULL,paramObjFun = NULL)
{
newcol = evalConst(x,constFun,paramConsFun)
if (phase == 1) output = -lpdual%*%newcol
if (phase == 2) output =  lpdual%*%newcol -  objFun(x,paramObjFun)
return(output)
}
#' phase2
#'
#' @param initBFS
#' @param objFun
#' @param constFun
#' @param constRHS
#' @param constDir
#' @param constLambda
#' @param objLambda
#' @param paramConsFun
#' @param paramObjFun
#' @param gamma
#' @param C
#' @param IterMax
#' @param err
#' @param rerr
#' @param factor
#' @param scale
#' @param objFuncIndic
#'
#' @return
#' @export
#' @importFrom lpSolve lp
#' @importFrom GenSA GenSA
#'
#' @examples
#' ####
#' #### Finding a the optimal probability measure (p,x) to the problem
#' ####
#' #### max P(X > c)
#' #### s.t. sum(p)  = 1
#' ####      sum(px) = 1
#' ####      sum(px^2) = 2
#' ####
#' #### where c is the 90th percentile of a standard exponential distribution
#' #### Note that the solution to this problem is known (see Theorem 3.3 of Bertsimas and Popescu)
#'
#' # Function and parameters for the integral of the objective
#' objFun <- function(x,...) return(as.numeric(paramObjFun$c <= x))
#' paramObjFun <- list(c = qexp(0.9,rate))
#'
#' # Function for the integrals of the constraints inequality
#' constFun = rep(list(
#' function(x,...) 1,
#' function(x,...) x,
#' function(x,...) x^2
#' ),2)
#'
#' # Direction of the inequality constraints
#' constDir <- rep(c("<=", ">="), each = 3)
#'
#' # Values on the RHS of each inequality
#' # here we choose the moment of order 0, 1, and 2 of an exponential distribution
#' rate <- 1
#' mu0 <- 1
#' mu1 <- 1/rate
#' mu2 <- 2/rate^2
#'
#' # Lambdas for the objective function and the constraints functions
#' constLambda <- rep(c(0,0,1),2)
#' objLambda <- 0
#'
#' # Get a basic feasible solution
#' initBFS  <-  phase1(constFun, constRHS,constDir)
#'
#' # Check feasibility
#' with(initBFS, c(sum(p), sum(p*x), sum(p*x^2)))
#'
#' # Solve the optimization program of interest
#' output <- phase2(initBFS, objFun, constFun, constRHS,
#'                      constDir, constLambda, objLambda,
#'                      paramObjFun = paramObjFun, objFuncIndic = TRUE)
#'
#' # Check that the output matches the analytical solution
#' CMsquare <- (mu2 - mu1^2)/mu1^2
#' delta <-  (paramObjFun$c/mu1-1)
#'
#' data.frame(Algorithm = output$lB, Analytical = CMsquare/(CMsquare + delta^2))
phase2 <- function(initBFS,
objFun,
constFun,
constRHS,
constDir,
constLambda,
objLambda,
paramConsFun = NULL,
paramObjFun = NULL,
gamma = NULL,
C        = 1e4,
IterMax   = 100,
err       = 1e-6,
rerr      = 1e-4,
factor    = 1,
objFuncIndic = FALSE)
{
###
### Step 0 - Initialization of the optimization problem
###
# Initialize output
output <- list(p         = 0,
x         = 0,
s         = 0,
lastx     = NA,
lpdual    = rep(0,length(constFun)),
feasible  = initBFS$feasible,
status    = 1,
nIter     = 0,
dual_lB   = Inf,
primal_uB = -Inf,
eps       = Inf)
# If there is no initial feasible solution, the program in unbounded
if (!initBFS$feasible) return(output)
uB <-  Inf
lB <- -Inf
s  <- 0
N <- length(constRHS)
# Initialize the x
x <- initBFS$x
feasible <- initBFS$feasible
# Initialize the objective function of the Master Program
objectiveIn     <- rep(0,length(x)+1)
objectiveIn[1]  <- objLambda
objectiveIn[-1] <- sapply(x,objFun,paramObjFun)
# Initialize the constraints matrix of the Master Program
constMat     <- matrix(0,length(objectiveIn), nrow = length(constRHS))
constMat[,1] <- constLambda   # which we defined as the last one in f.con
constMat[,-1] <- evalConst(x,constFun,paramConsFun)
for (k in 1:IterMax)
{
###
### Master Program
###
outOpt <- lp(direction = "max",
objectiveIn,
constMat,
constDir,
constRHS,
compute.sens = TRUE)
if (outOpt$status !=0)
{
print(paste("The master problem does not converge. Error status " ,outOpt$status))
x <- x[-length(x)]
status <- outOpt$status
if (k ==1) xnew  = eps  =NA
break
}
s      <- outOpt$solution[1]
p      <- outOpt$solution[-1]
lpdual <- outOpt$duals[1:N]
lB     <- outOpt$objval
###
### Sub-program
###
if (objFuncIndic & paramObjFun$c <= C)
{
tmp <- NULL
tmp[[1]] <- GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = 0,
upper     = paramObjFun$c,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
tmp[[2]] <- GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = paramObjFun$c,
upper     = C,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
inOpt <- tmp[[ which.min(c(tmp[[1]]$value,tmp[[2]]$value)) ]]
} else
inOpt <-GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = 0,
upper     = C,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
xnew <- inOpt$par
eps  <- -inOpt$value
if (is.null(gamma)) status <- eps > err
else {
uB <- min(gamma*eps +  lB, uB)   ;
evalConst = function(x,constFun,paramConstFun){
output = matrix(0,nrow= length(constFun),ncol = length(x))
for (i in 1:length(constFun)) output[i,] = do.call(constFun[[i]],list(x = x,paramConstFun = paramConstFun))
return(output)
}
innerOptimizationFunction = function(x,lpdual,phase,constFun,paramConsFun, objFun = NULL,paramObjFun = NULL)
{
newcol = evalConst(x,constFun,paramConsFun)
if (phase == 1) output = -lpdual%*%newcol
if (phase == 2) output =  lpdual%*%newcol -  objFun(x,paramObjFun)
return(output)
}
#' phase2
#'
#' @param initBFS
#' @param objFun
#' @param constFun
#' @param constRHS
#' @param constDir
#' @param constLambda
#' @param objLambda
#' @param paramConsFun
#' @param paramObjFun
#' @param gamma
#' @param C
#' @param IterMax
#' @param err
#' @param rerr
#' @param factor
#' @param scale
#' @param objFuncIndic
#'
#' @return
#' @export
#' @importFrom lpSolve lp
#' @importFrom GenSA GenSA
#'
#' @examples
#' ####
#' #### Finding a the optimal probability measure (p,x) to the problem
#' ####
#' #### max P(X > c)
#' #### s.t. sum(p)  = 1
#' ####      sum(px) = 1
#' ####      sum(px^2) = 2
#' ####
#' #### where c is the 90th percentile of a standard exponential distribution
#' #### Note that the solution to this problem is known (see Theorem 3.3 of Bertsimas and Popescu)
#'
#' # Function and parameters for the integral of the objective
#' objFun <- function(x,...) return(as.numeric(paramObjFun$c <= x))
#' paramObjFun <- list(c = qexp(0.9,rate))
#'
#' # Function for the integrals of the constraints inequality
#' constFun = rep(list(
#' function(x,...) 1,
#' function(x,...) x,
#' function(x,...) x^2
#' ),2)
#'
#' # Direction of the inequality constraints
#' constDir <- rep(c("<=", ">="), each = 3)
#'
#' # Values on the RHS of each inequality
#' # here we choose the moment of order 0, 1, and 2 of an exponential distribution
#' rate <- 1
#' mu0 <- 1
#' mu1 <- 1/rate
#' mu2 <- 2/rate^2
#'
#' # Lambdas for the objective function and the constraints functions
#' constLambda <- rep(c(0,0,1),2)
#' objLambda <- 0
#'
#' # Get a basic feasible solution
#' initBFS  <-  phase1(constFun, constRHS,constDir)
#'
#' # Check feasibility
#' with(initBFS, c(sum(p), sum(p*x), sum(p*x^2)))
#'
#' # Solve the optimization program of interest
#' output <- phase2(initBFS, objFun, constFun, constRHS,
#'                      constDir, constLambda, objLambda,
#'                      paramObjFun = paramObjFun, objFuncIndic = TRUE)
#'
#' # Check that the output matches the analytical solution
#' CMsquare <- (mu2 - mu1^2)/mu1^2
#' delta <-  (paramObjFun$c/mu1-1)
#'
#' data.frame(Algorithm = output$lB, Analytical = CMsquare/(CMsquare + delta^2))
phase2 <- function(initBFS,
objFun,
constFun,
constRHS,
constDir,
constLambda,
objLambda,
paramConsFun = NULL,
paramObjFun = NULL,
gamma = NULL,
C        = 1e4,
IterMax   = 100,
err       = 1e-6,
rerr      = 1e-4,
factor    = 1,
objFuncIndic = FALSE)
{
###
### Step 0 - Initialization of the optimization problem
###
# Initialize output
output <- list(p         = 0,
x         = 0,
s         = 0,
lastx     = NA,
lpdual    = rep(0,length(constFun)),
feasible  = initBFS$feasible,
status    = 1,
nIter     = 0,
dual_lB   = Inf,
primal_uB = -Inf,
eps       = Inf)
# If there is no initial feasible solution, the program in unbounded
if (!initBFS$feasible) return(output)
uB <-  Inf
lB <- -Inf
s  <- 0
N <- length(constRHS)
# Initialize the x
x <- initBFS$x
feasible <- initBFS$feasible
# Initialize the objective function of the Master Program
objectiveIn     <- rep(0,length(x)+1)
objectiveIn[1]  <- objLambda
objectiveIn[-1] <- sapply(x,objFun,paramObjFun)
# Initialize the constraints matrix of the Master Program
constMat     <- matrix(0,length(objectiveIn), nrow = length(constRHS))
constMat[,1] <- constLambda   # which we defined as the last one in f.con
constMat[,-1] <- evalConst(x,constFun,paramConsFun)
for (k in 1:IterMax)
{
###
### Master Program
###
outOpt <- lp(direction = "max",
objectiveIn,
constMat,
constDir,
constRHS,
compute.sens = TRUE)
if (outOpt$status !=0)
{
print(paste("The master problem does not converge. Error status " ,outOpt$status))
x <- x[-length(x)]
status <- outOpt$status
if (k ==1) xnew  = eps  =NA
break
}
s      <- outOpt$solution[1]
p      <- outOpt$solution[-1]
lpdual <- outOpt$duals[1:N]
lB     <- outOpt$objval
###
### Sub-program
###
if (objFuncIndic & paramObjFun$c <= C)
{
tmp <- NULL
tmp[[1]] <- GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = 0,
upper     = paramObjFun$c,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
tmp[[2]] <- GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = paramObjFun$c,
upper     = C,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
inOpt <- tmp[[ which.min(c(tmp[[1]]$value,tmp[[2]]$value)) ]]
} else
inOpt <-GenSA(par       = 0,
fn        = innerOptimizationFunction,# GenSA for GLOBAL max
lower     = 0,
upper     = C,
phase     = 2,
lpdual    = lpdual,
constFun = constFun,
paramConsFun = paramConsFun,
objFun   = objFun,
paramObjFun   = paramObjFun)
xnew <- inOpt$par
eps  <- -inOpt$value
if (is.null(gamma)) status <- eps > err
else {
uB <- min(gamma*eps +  lB, uB)   ;
}
}
c
))))
library(GLP)
library(GLP)
library(GLP)
library(GLP)
library(GLP)
library(GLP)
