d3    = DistributionPty::Dlhorror(a, 3)
m0 = 1-DistributionPty::Dlhorror(a, 0)
m1 = DistributionPty::UpperTrunclHorrorMoment(a,1, n=1e5)
m2 = DistributionPty::UpperTrunclHorrorMoment(a,2, n=1e5)
m3 = DistributionPty::UpperTrunclHorrorMoment(a,3, n=1e5)
truth  = data.frame(d3,-d2,d1,m0,m1,m2,m3)
truth
d2
d1    = DistributionPty::Dlhorror(a, 1)
d2    = -DistributionPty::Dlhorror(a, 2)
d3    = DistributionPty::Dlhorror(a, 3)
m0 = 1-DistributionPty::Dlhorror(a, 0)
m1 = DistributionPty::UpperTrunclHorrorMoment(a,1, n=1e5)
m2 = DistributionPty::UpperTrunclHorrorMoment(a,2, n=1e5)
m3 = DistributionPty::UpperTrunclHorrorMoment(a,3, n=1e5)
truth  = data.frame(d3,d2,d1,m0,m1,m2,m3)
load("data/log_Hill_data_optimparam.Rdata") # Obtain by running getOptimParam.R
load("data/log_Hill_Horror_dist.Rdata") # Obtain by running getDataFigure1.R
d1    = DistributionPty::Dlhorror(a, 1)
d2    = -DistributionPty::Dlhorror(a, 2)
d3    = DistributionPty::Dlhorror(a, 3)
m0 = 1-DistributionPty::Dlhorror(a, 0)
m1 = DistributionPty::UpperTrunclHorrorMoment(a,1, n=1e5)
m2 = DistributionPty::UpperTrunclHorrorMoment(a,2, n=1e5)
m3 = DistributionPty::UpperTrunclHorrorMoment(a,3, n=1e5)
truth  = data.frame(d3,d2,d1,m0,m1,m2,m3)
save(bootSample,optim_param,truth, designTab, file = "data/log_Hill_data_optimparam.Rdata")
save(optim,optim_param,optim_outDist,
P,a,m,d,truth,
objFun,constFun,
file = "data/MaxLogdHorrorDist_TailProb.Rdata")
load("data/MaxLogdHorrorDist_TailProb.Rdata")
save(optim,optim_param,optim_outDist,
P,a,m,d,truth,
objFun,constFun,
file = "data/MaxLogdHorrorDist_TailProb.Rdata")
head(optim)
library(latex2exp)
library(ggplot2)
library(magrittr)
load("data/log_Hill_data_optimparam.Rdata")
load("data/MaxLogdHorrorDist_TailProb.Rdata")
optim <- optim[-which(apply(optim, 1, function(x)all(is.na(x)))),]
J1 <- 0:3
J2 <- 3:1
N <- length(J1) + length(J2)
ParamNames <- names(optim)[1:N]
Data <- transform(optim,
nparam = as.factor(rowSums(optim[,1:N])),
J1empty = rowSums(optim[, c("m0", "m1", "m2", "m3")])==0,
J2empty = rowSums(optim[, c("d3", "d2", "d1")])==0,
RelErr = with(optim,(lB - (1-P))/(1-P)),
D  = as.factor(D),
param.inc = apply(optim[,1:N], 1,function(mat){paste(subset(ParamNames,unlist(mat)),collapse = ",")})
)
convexData <- subset(Data, (D==2) & (!d3) & (d2) & d1 & m0 & (!m1) & (!m2) & (!m3) )
maxErrRel <- expand.grid(D = 0:5, P = P) %>% transform(maxErrRel = P/(1-P))
plot <- ggplot(data = Data, aes(x = D, y = RelErr,text = param.inc,size = J1empty)) +
geom_jitter(width = 0.3,color = alpha("black",1/5)) +
geom_hline(data = maxErrRel, aes(yintercept = maxErrRel))+
# geom_point(data = convexData, aes(x = D, y = RelErr, color="Convex Approach") ) +
facet_wrap(~P,ncol = 4,nrow = 4,
labeller = as_labeller(c("0.9" = "p = 90",
"0.99" = " p = 99",
"0.999" = " p = 99.9",
"0.9999" = " p = 99.99")))   +
coord_trans(y = "log10", limy = c(0.01,1.5e4)) +
scale_y_continuous(breaks =   c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4),
labels = c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4)) +
scale_x_discrete(breaks =   seq(0,5,by = 2)) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = TeX('Subset $\\mathit{J_1}$')) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = "", color="") +
scale_size_discrete(labels = c("At least one moment constraint","No moment constraint"))
plot
Data <- transform(optim,
nparam = as.factor(rowSums(optim[,1:N])),
J1empty = rowSums(optim[, c("m0", "m1", "m2", "m3")])==0,
J2empty = rowSums(optim[, c("d3", "d2", "d1")])==0,
RelErr = with(optim,(lB - (1-P))/(1-P)),
D  = as.factor(D),
param.inc = apply(optim[,1:N], 1,function(mat){paste(subset(ParamNames,unlist(mat)),collapse = ",")})
)
library(latex2exp)
library(ggplot2)
library(magrittr)
load("data/log_Hill_data_optimparam.Rdata")
load("data/MaxLogdHorrorDist_TailProb.Rdata")
optim <- optim[-which(apply(optim, 1, function(x)all(is.na(x)))),]
J1 <- 0:3
J2 <- 3:1
N <- length(J1) + length(J2)
ParamNames <- names(optim)[1:N]
Data <- transform(optim,
nparam = as.factor(rowSums(optim[,1:N])),
J1empty = rowSums(optim[, c("m0", "m1", "m2", "m3")])==0,
J2empty = rowSums(optim[, c("d3", "d2", "d1")])==0,
RelErr = with(optim,(bound - (1-P))/(1-P)),
D  = as.factor(D),
param.inc = apply(optim[,1:N], 1,function(mat){paste(subset(ParamNames,unlist(mat)),collapse = ",")})
)
convexData <- subset(Data, (D==2) & (!d3) & (d2) & d1 & m0 & (!m1) & (!m2) & (!m3) )
maxErrRel <- expand.grid(D = 0:5, P = P) %>% transform(maxErrRel = P/(1-P))
plot <- ggplot(data = Data, aes(x = D, y = RelErr,text = param.inc,size = J1empty)) +
geom_jitter(width = 0.3,color = alpha("black",1/5)) +
geom_hline(data = maxErrRel, aes(yintercept = maxErrRel))+
# geom_point(data = convexData, aes(x = D, y = RelErr, color="Convex Approach") ) +
facet_wrap(~P,ncol = 4,nrow = 4,
labeller = as_labeller(c("0.9" = "p = 90",
"0.99" = " p = 99",
"0.999" = " p = 99.9",
"0.9999" = " p = 99.99")))   +
coord_trans(y = "log10", limy = c(0.01,1.5e4)) +
scale_y_continuous(breaks =   c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4),
labels = c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4)) +
scale_x_discrete(breaks =   seq(0,5,by = 2)) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = TeX('Subset $\\mathit{J_1}$')) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = "", color="") +
scale_size_discrete(labels = c("At least one moment constraint","No moment constraint"))
plot
ggsave(plot, file = "pics/Figure3.pdf", width = 10,height = 5,dpi=300)
library(plyr)
Table <- ddply(Data, .(P,D), .fun = function(x){
index_min <- which.min(x$RelErr)
row_min <- x[index_min, ]
J2_star <- J2[unlist(row_min[1:length(J2)])] %>% toString()
J1_star <- J1[unlist(row_min[length(J2) + 1:length(J1)])] %>% toString()
if (length(J2_star) ==0) J2_star = ' '
if (length(J1_star) ==0) J2_star = ' '
Z_star <- format(min(row_min$uB,row_min$lB), scientific=TRUE, digits =3)
data.frame(J1 = paste0("{",J1_star,"}"), J2 = paste0("{",J2_star,"}"), Z_star, row_min$RelErr)
})
Table$P <- Table$P*100
names(Table) <- c("P", "D", "J1", "J2","Optimal Objective Value", "Relative Error")
library(xtable)
library(dplyr)
display <- c(rep("d",4), "s","E")
for (p in P*100){
file <- paste0("tables/Transformed_Hill_Horror_TailProb_best_",p,".tex")
table <- subset(Table, p == P)%>% select(-P)
align  <- c(rep("|c",ncol(table)+1),"|")
xtable(table, align = align, digits = 3) %>% print(include.rownames=FALSE, type = "latex",file = file)
# We need to replace the tables by subtables (our way around uses unix commands)
command_1 <- paste0("sed -i '' -- 's/begin{table}\\[ht\\]/begin{subtable}{\\\\textwidth}/g' ",file)
system(command_1)
command_2 <- paste0("sed -i '' -- 's/end{table}/end{subtable}/g' ",file)
system(command_2)
# We need to add the subcaption to the subtables (our way around uses unix commands)
command_3 <- paste0("sed -i '' -- 's/D \\& J1 \\& J2/\\$D\\$ \\& \\$\\\\mathcal J\\_1\\^\\*\\$ \\& \\$\\\\mathcal J\\_2\\^\\*\\$/g' ",file)
system(command_3)
# Make the right column names
command_4 <- paste0("sed -i '' -- 's/end{tabular}/end{tabular}\\\\subcaption{$p = ",p," $}/g' ",file)
system(command_4)
}
Table
library(plyr)
Table <- ddply(Data, .(P,D), .fun = function(x){
index_min <- which.min(x$RelErr)
row_min <- x[index_min, ]
J2_star <- J2[unlist(row_min[1:length(J2)])] %>% toString()
J1_star <- J1[unlist(row_min[length(J2) + 1:length(J1)])] %>% toString()
if (length(J2_star) ==0) J2_star = ' '
if (length(J1_star) ==0) J2_star = ' '
Z_star <- format(bound, scientific=TRUE, digits =3)
data.frame(J1 = paste0("{",J1_star,"}"), J2 = paste0("{",J2_star,"}"), Z_star, row_min$RelErr)
})
library(plyr)
Table <- ddply(Data, .(P,D), .fun = function(x){
index_min <- which.min(x$RelErr)
row_min <- x[index_min, ]
J2_star <- J2[unlist(row_min[1:length(J2)])] %>% toString()
J1_star <- J1[unlist(row_min[length(J2) + 1:length(J1)])] %>% toString()
if (length(J2_star) ==0) J2_star = ' '
if (length(J1_star) ==0) J2_star = ' '
Z_star <- format(row_min$bound, scientific=TRUE, digits =3)
data.frame(J1 = paste0("{",J1_star,"}"), J2 = paste0("{",J2_star,"}"), Z_star, row_min$RelErr)
})
Table$P <- Table$P*100
names(Table) <- c("P", "D", "J1", "J2","Optimal Objective Value", "Relative Error")
Table
library(xtable)
library(dplyr)
display <- c(rep("d",4), "s","E")
for (p in P*100){
file <- paste0("tables/Transformed_Hill_Horror_TailProb_best_",p,".tex")
table <- subset(Table, p == P)%>% select(-P)
align  <- c(rep("|c",ncol(table)+1),"|")
xtable(table, align = align, digits = 3) %>% print(include.rownames=FALSE, type = "latex",file = file)
# We need to replace the tables by subtables (our way around uses unix commands)
command_1 <- paste0("sed -i '' -- 's/begin{table}\\[ht\\]/begin{subtable}{\\\\textwidth}/g' ",file)
system(command_1)
command_2 <- paste0("sed -i '' -- 's/end{table}/end{subtable}/g' ",file)
system(command_2)
# We need to add the subcaption to the subtables (our way around uses unix commands)
command_3 <- paste0("sed -i '' -- 's/D \\& J1 \\& J2/\\$D\\$ \\& \\$\\\\mathcal J\\_1\\^\\*\\$ \\& \\$\\\\mathcal J\\_2\\^\\*\\$/g' ",file)
system(command_3)
# Make the right column names
command_4 <- paste0("sed -i '' -- 's/end{tabular}/end{tabular}\\\\subcaption{$p = ",p," $}/g' ",file)
system(command_4)
}
library(devtools)
library(GLP)
devtools::document()
library(GLP)
library(devtools)
devtools::document()
# Function and parameters for the integral of the objective
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
rate <- 1
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
# Function for the integrals of the constraints inequality
constFun = rep(list(
function(x) 1,
function(x) x,
function(x) x^2
),2)
# Direction of the inequality constraints
constDir <- rep(c("<=", ">="), each = 3)
mu0 <- 1
mu1 <- 1/rate
mu2 <- 2/rate^2
# Lambdas for the objective function and the constraints functions
constLambda <- rep(c(0,0,0),2)
objLambda <- 0
# Get a basic feasible solution
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
rate <- 1
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
# Function for the integrals of the constraints inequality
constFun = rep(list(
function(x) 1,
function(x) x,
function(x) x^2
),2)
# Direction of the inequality constraints
constDir <- rep(c("<=", ">="), each = 3)
constDir
constRHS <- rep(c(1,1,2), each = 2)
constRHS
constRHS <- rep(c(1,1,2), 2)
constRHS
# Direction of the inequality constraints
constDir <- rep(c("<=", ">="), each = 3)
# Bounds on the inequalities
constRHS <- rep(c(1,1,2), 2)
# Values on the RHS of each inequality
# here we choose the moment of order 0, 1, and 2 of an exponential distribution
rate <- 1
mu0 <- 1
mu1 <- 1/rate
mu2 <- 2/rate^2
# Lambdas for the objective function and the constraints functions
constLambda <- rep(c(0,0,0),2)
objLambda <- 0
# Get a basic feasible solution
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
# Check feasibility
with(initBFS, c(sum(p), sum(p*x), sum(p*x^2)))
# Solve the optimization program of interest
output <- phase2(initBFS,
objFun,
constFun,
constRHS,
constDir,
constLambda,
objLambda,
C = 1000,
err = 5e-10)
# Check that the output matches the analytical solution
CMsquare <- (mu2 - mu1^2)/mu1^2
delta <-  (d/mu1-1)
data.frame(Algorithm = output$lB, Analytical = CMsquare/(CMsquare + delta^2))
CMsquare
delta
data.frame(Algorithm = output$bound, Analytical = CMsquare/(CMsquare + delta^2))
constDir <- rep("=", 3)
# Bounds on the inequalities
constRHS <- rep(c(1,1,2), 1)
constRHS
constDir
# Values on the RHS of each inequality
# here we choose the moment of order 0, 1, and 2 of an exponential distribution
rate <- 1
mu0 <- 1
mu1 <- 1/rate
mu2 <- 2/rate^2
constLambda <- rep(c(0,0,0),``)
constLambda <- rep(c(0,0,0),1)
objLambda <- 0
# Get a basic feasible solution
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
rate <- 1
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
# Function for the integrals of the constraints inequality
constFun = rep(list(
function(x) 1,
function(x) x,
function(x) x^2
),1)
# Direction of the inequality constraints
constDir <- rep("=", 3)
constFun
constDir <- rep("=", 3)
constDir
constRHS <- rep(c(1,1,2), 1)
constRHS
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
constFun
constRHS
constDir
constLambda
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
debugonce("phase1")
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
constMat
outOpt
constRHS
constDir
constMAt
constMat
library(GLP)
rate <- 1
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
# Function for the integrals of the constraints inequality
constFun <- rep(list(
function(x) 1,
function(x) x,
function(x) x^2
),1)
# Direction of the inequality constraints
constDir <- rep("=", 3)
# Bounds on the inequalities
constRHS <- rep(c(1,1,2), 1)
# Values on the RHS of each inequality
# here we choose the moment of order 0, 1, and 2 of an exponential distribution
rate <- 1
mu0 <- 1
mu1 <- 1/rate
mu2 <- 2/rate^2
# Lambdas for the objective function and the constraints functions
constLambda <- rep(c(0,0,0),1)
objLambda <- 0
# Get a basic feasible solution
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
library(GLP)
# Function and parameters for the integral of the objective
rate <- 1
d <- qexp(0.9,rate)
objFun <- function(x) return(as.numeric(d <= x))
# Function for the integrals of the constraints inequality
constFun = rep(list(
function(x) 1,
function(x) x,
function(x) x^2
),2)
# Direction of the inequality constraints
constDir <- rep(c("<=", ">="), each = 3)
# Bounds on the inequalities
constRHS <- rep(c(1,1,2), 2)
# Values on the RHS of each inequality
# here we choose the moment of order 0, 1, and 2 of an exponential distribution
rate <- 1
mu0 <- 1
mu1 <- 1/rate
mu2 <- 2/rate^2
# Lambdas for the objective function and the constraints functions
constLambda <- rep(c(0,0,0),2)
objLambda <- 0
# Get a basic feasible solution
initBFS  <-  phase1(constFun, constRHS,constDir, constLambda)
# Check feasibility
with(initBFS, c(sum(p), sum(p*x), sum(p*x^2)))
# Solve the optimization program of interest
output <- phase2(initBFS,
objFun,
constFun,
constRHS,
constDir,
constLambda,
objLambda,
C = 1000,
err = 5e-10)
# Check that the output matches the analytical solution
CMsquare <- (mu2 - mu1^2)/mu1^2
delta <-  (d/mu1-1)
data.frame(Algorithm = output$bound, Analytical = CMsquare/(CMsquare + delta^2))
devtools::document()
setwd("~/Projects/R/MonotoneDerivatives/")
library(latex2exp)
library(ggplot2)
library(magrittr)
load("data/log_Hill_data_optimparam.Rdata")
load("data/MaxLogdHorrorDist_TailProb.Rdata")
optim <- optim[-which(apply(optim, 1, function(x)all(is.na(x)))),]
J1 <- 0:3
J2 <- 3:1
N <- length(J1) + length(J2)
ParamNames <- names(optim)[1:N]
Data <- transform(optim,
nparam = as.factor(rowSums(optim[,1:N])),
J1empty = rowSums(optim[, c("m0", "m1", "m2", "m3")])==0,
J2empty = rowSums(optim[, c("d3", "d2", "d1")])==0,
RelErr = with(optim,(bound - (1-P))/(1-P)),
D  = as.factor(D),
param.inc = apply(optim[,1:N], 1,function(mat){paste(subset(ParamNames,unlist(mat)),collapse = ",")})
)
convexData <- subset(Data, (D==2) & (!d3) & (d2) & d1 & m0 & (!m1) & (!m2) & (!m3) )
maxErrRel <- expand.grid(D = 0:5, P = P) %>% transform(maxErrRel = P/(1-P))
plot <- ggplot(data = Data, aes(x = D, y = RelErr,text = param.inc,size = J1empty)) +
geom_jitter(width = 0.3,color = alpha("black",1/5)) +
geom_hline(data = maxErrRel, aes(yintercept = maxErrRel))+
geom_point(data = convexData, aes(x = D, y = RelErr, color="Convex Approach") ) +
facet_wrap(~P,ncol = 4,nrow = 4,
labeller = as_labeller(c("0.9" = "p = 90",
"0.99" = " p = 99",
"0.999" = " p = 99.9",
"0.9999" = " p = 99.99")))   +
coord_trans(y = "log10", limy = c(0.01,1.5e4)) +
scale_y_continuous(breaks =   c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4),
labels = c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4)) +
scale_x_discrete(breaks =   seq(0,5,by = 2)) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = TeX('Subset $\\mathit{J_1}$')) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = "", color="") +
scale_size_discrete(labels = c("At least one moment constraint","No moment constraint"))
plot
ggsave(plot, file = "pics/Figure3.pdf", width = 10,height = 5,dpi=300)
library(latex2exp)
library(ggplot2)
library(magrittr)
load("data/log_Hill_data_optimparam.Rdata")
load("data/MaxLogdHorrorDist_TailProb.Rdata")
# Remove a row with only NA's
optim <- optim[-which(apply(optim, 1, function(x)all(is.na(x)))),]
J1 <- 0:3
J2 <- 3:1
N <- length(J1) + length(J2)
ParamNames <- names(optim)[1:N]
Data <- transform(optim,
nparam = as.factor(rowSums(optim[,1:N])),
J1empty = rowSums(optim[, c("m0", "m1", "m2", "m3")])==0,
J2empty = rowSums(optim[, c("d3", "d2", "d1")])==0,
RelErr = with(optim,(bound - (1-P))/(1-P)),
D  = as.factor(D),
param.inc = apply(optim[,1:N], 1,function(mat){paste(subset(ParamNames,unlist(mat)),collapse = ",")})
)
# Comparing to previous paper approach
# Lam H, Mottet C (2017) Tail analysis without parametric models: A worst-case perspective. Operations
# Research https://doi.org/10.1287/opre.2017.1643.
convexData <- subset(Data, (D==2) & (!d3) & (d2) & d1 & m0 & (!m1) & (!m2) & (!m3) )
###
### Plot Figure 3
###
maxErrRel <- expand.grid(D = 0:5, P = P) %>% transform(maxErrRel = P/(1-P))
plot <- ggplot(data = Data, aes(x = D, y = RelErr,text = param.inc,size = J1empty)) +
geom_jitter(width = 0.3,color = alpha("black",1/5)) +
geom_hline(data = maxErrRel, aes(yintercept = maxErrRel))+
#geom_point(data = convexData, aes(x = D, y = RelErr, color="Convex Approach") ) +
facet_wrap(~P,ncol = 4,nrow = 4,
labeller = as_labeller(c("0.9" = "p = 90",
"0.99" = " p = 99",
"0.999" = " p = 99.9",
"0.9999" = " p = 99.99")))   +
coord_trans(y = "log10", limy = c(0.01,1.5e4)) +
scale_y_continuous(breaks =   c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4),
labels = c(0.25,1,2.5,10,25,1e2,250,1e3,2500,1e4)) +
scale_x_discrete(breaks =   seq(0,5,by = 2)) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = TeX('Subset $\\mathit{J_1}$')) +
labs(x = TeX('$D$'), y = TeX("Relative error"), size = "", color="") +
scale_size_discrete(labels = c("At least one moment constraint","No moment constraint"))
plot
ggsave(plot, file = "pics/Figure3.pdf", width = 10,height = 5,dpi=300)
###
### Get best subsets J1* and J2*
###
library(plyr)
Table <- ddply(Data, .(P,D), .fun = function(x){
index_min <- which.min(x$RelErr)
row_min <- x[index_min, ]
J2_star <- J2[unlist(row_min[1:length(J2)])] %>% toString()
J1_star <- J1[unlist(row_min[length(J2) + 1:length(J1)])] %>% toString()
if (length(J2_star) ==0) J2_star = ' '
if (length(J1_star) ==0) J2_star = ' '
Z_star <- format(row_min$bound, scientific=TRUE, digits =3)
data.frame(J1 = paste0("{",J1_star,"}"), J2 = paste0("{",J2_star,"}"), Z_star, row_min$RelErr)
})
Table$P <- Table$P*100
names(Table) <- c("P", "D", "J1", "J2","Optimal Objective Value", "Relative Error")
# Create the LaTex Tables
library(xtable)
library(dplyr)
display <- c(rep("d",4), "s","E")
for (p in P*100){
file <- paste0("tables/Transformed_Hill_Horror_TailProb_best_",p,".tex")
table <- subset(Table, p == P)%>% select(-P)
align  <- c(rep("|c",ncol(table)+1),"|")
xtable(table, align = align, digits = 3) %>% print(include.rownames=FALSE, type = "latex",file = file)
# We need to replace the tables by subtables (our way around uses unix commands)
command_1 <- paste0("sed -i '' -- 's/begin{table}\\[ht\\]/begin{subtable}{\\\\textwidth}/g' ",file)
system(command_1)
command_2 <- paste0("sed -i '' -- 's/end{table}/end{subtable}/g' ",file)
system(command_2)
# We need to add the subcaption to the subtables (our way around uses unix commands)
command_3 <- paste0("sed -i '' -- 's/D \\& J1 \\& J2/\\$D\\$ \\& \\$\\\\mathcal J\\_1\\^\\*\\$ \\& \\$\\\\mathcal J\\_2\\^\\*\\$/g' ",file)
system(command_3)
# Make the right column names
command_4 <- paste0("sed -i '' -- 's/end{tabular}/end{tabular}\\\\subcaption{$p = ",p," $}/g' ",file)
system(command_4)
}
